{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例\n",
    "接下來的程式碼會示範如何在檢測到人臉關鍵點的情況下，做出給人臉戴上太陽眼鏡的濾鏡效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 colab 環境的同學請執行以下程式碼\n",
    "# %tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n",
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "# import os\n",
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n",
    "# %cd 'gdrive/My Drive'\n",
    "# os.system(\"mkdir cupoy_cv_part4\") # 可以自己改路徑\n",
    "# %cd cupoy_cv_part4 # 可以自己改路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 讀取資料集以及做前處理的函數\n",
    "def load_data(dirname):\n",
    "    # 讀取 csv 文件\n",
    "    data = pd.read_csv(dirname)\n",
    "    # 過濾有缺失值的 row\n",
    "    data = data.dropna()\n",
    "\n",
    "    # 將圖片像素值讀取為 numpy array 的形態\n",
    "    data['Image'] = data['Image'].apply(lambda img: np.fromstring(img, sep=' ')).values \n",
    "\n",
    "    # 單獨把圖像 array 抽取出來\n",
    "    imgs = np.vstack(data['Image'].values)/255\n",
    "    # reshape 為 96 x 96\n",
    "    imgs = imgs.reshape(data.shape[0], 96, 96)\n",
    "    # 轉換為 float\n",
    "    imgs = imgs.astype(np.float32)\n",
    "    \n",
    "    # 提取坐標的部分\n",
    "    points = data[data.columns[:-1]].values\n",
    "\n",
    "    # 轉換為 float\n",
    "    points = points.astype(np.float32)\n",
    "\n",
    "    # normalize 坐標值到 [-0.5, 0.5]\n",
    "    points = points/96 - 0.5\n",
    "    \n",
    "    return imgs, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料\n",
    "imgs_train, points_train = load_data(dirname = 'training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 回傳定義好的 model 的函數\n",
    "def get_model():\n",
    "    # 定義人臉關鍵點檢測網路\n",
    "    model = Sequential()\n",
    "\n",
    "    # 定義神經網路的輸入\n",
    "    model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(96, 96, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 最後輸出 30 維的向量，也就是 15 個關鍵點的值\n",
    "    model.add(Dense(30))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.load_weights(\"best_weights.h5\") # 載入之前 train 好的權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_img = imgs_train[0] # 選一張圖片做人臉濾鏡的樣本\n",
    "sample_point = points_train[0]\n",
    "# 在灰階圖像上畫關鍵點的函數\n",
    "def plot_keypoints(img, points):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for i in range(0,30,2):\n",
    "        plt.scatter((points[i] + 0.5)*96, (points[i+1]+0.5)*96, color='red')\n",
    "        plt.text((points[i] + 0.5)*96, (points[i+1]+0.5-0.05)*96, str(int(i/2))) # 把關鍵點 index 畫出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keypoints(sample_img, sample_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我們應用人臉關鍵點時，不管資料集文件沒有寫清楚，都可以通過把 index 畫出來的方式來理解關鍵點的順序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunglasses = cv2.imread('sunglasses.png', cv2.IMREAD_UNCHANGED) # cv2.IMREAD_UNCHANGED 表示要讀取圖像透明度的 channel\n",
    "plt.imshow(sunglasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來我們利用預測到的人臉關鍵點信息，把這個太陽眼鏡放到 sample_img 上\n",
    "\n",
    "**Note**: 這個太陽眼鏡的圖片必須是透明背景的 .png 哦，有興趣的同學也可以拿非透明背景的圖片來試看有什麼分別..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "landmarks = model.predict(sample_img.reshape(-1, 96, 96, 1)) # 預測人臉關鍵點\n",
    "landmarks = (landmarks + 0.5) * 96 # 將預測的人臉關鍵點的數值範圍由 -0.5 ~ 0.5 轉回 0 ~ 96\n",
    "key_pts = landmarks.reshape(-1, 2)\n",
    "\n",
    "face_img = cv2.cvtColor((sample_img*255).astype(np.uint8), cv2.COLOR_GRAY2BGR) # 將灰階圖像轉為 BGR\n",
    "\n",
    "# 以下示範如何用檢測到的關鍵點去定義要增加太陽眼鏡濾鏡的坐標，\n",
    "# 其中使用的 key_pts index 就是由 plot_keypoints 所畫出來的 index 觀察而來\n",
    "sunglass_top_x = int(key_pts[9, 0]) # 在這裡選右眉毛的最外側 (也就是第 9 index) 做太陽眼鏡的最左邊\n",
    "sunglass_w = int(abs(key_pts[9, 0] - key_pts[7, 0])) # 在這裡選右眉毛最外側到左眉毛最外側 (也就是第 7、9 index) 做為太陽眼鏡的寬\n",
    "sunglass_top_y = int((key_pts[9, 1] + key_pts[5, 1]) / 2) # y 和 h 也是類似的道理了\n",
    "sunglass_h = int(abs(key_pts[8, 1] - key_pts[10, 1]) / 2)\n",
    "\n",
    "new_sunglasses =  cv2.resize(sunglasses, (sunglass_w, sunglass_h), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "# roi 為要覆蓋太陽眼鏡的 BGR 人臉範圍\n",
    "roi = face_img[sunglass_top_y:sunglass_top_y+sunglass_h, sunglass_top_x:sunglass_top_x+sunglass_w]\n",
    "\n",
    "# 找出非透明的 pixel\n",
    "ind = np.argwhere(new_sunglasses[:,:,3] > 0)\n",
    "\n",
    "# 把 roi 中每個 channel 非透明的地方替換為太陽眼鏡的 pixel\n",
    "for i in range(3):\n",
    "    roi[ind[:,0],ind[:,1],i] = new_sunglasses[ind[:,0],ind[:,1],i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(face_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如此就完成一個簡單的太陽眼鏡人臉濾鏡啦！\n",
    "\n",
    "實際應用中，人臉關鍵點檢測只是其實一個環節，要做到應用級別，至少還需要一個人臉檢測模型\n",
    "\n",
    "而人臉相關的應用算是相對比較成熟的領域，所以可以找到很多研究和開源代碼，本課程有推薦一些項目，有興趣的同學可以自行參考～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
